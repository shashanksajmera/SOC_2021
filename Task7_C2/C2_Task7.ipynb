{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcH1gcHUhS26",
        "cellView": "form"
      },
      "source": [
        "#@title <font size=\"5\"> ឵឵<i>← Install Required Libraries</font> { vertical-output: true }\n",
        "from IPython.display import clear_output\n",
        "import os, urllib.request\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "pathDoneCMD = f'{HOME}/doneCMD.sh'\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ttmg.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/yunooooo/gcct/master/res/ttmg.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ttmg.py\")\n",
        "\n",
        "from ttmg import (\n",
        "    loadingAn,\n",
        "    textAn,\n",
        ")\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Installing Dependencies...\", ty='twg')\n",
        "\n",
        "os.system('pip install bing-image-downloader')\n",
        "os.system('pip install face_recognition')\n",
        "from sklearn.cluster import DBSCAN\n",
        "from imutils import build_montages\n",
        "import numpy as np\n",
        "from bing_image_downloader import downloader\n",
        "from requests import exceptions\n",
        "from google.colab import drive\n",
        "import os\n",
        "from imutils import paths\n",
        "import pickle\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils.video import VideoStream\n",
        "import face_recognition\n",
        "import imutils\n",
        "import time\n",
        "\n",
        "clear_output()\n",
        "print('Installation finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSpTNXpcjth2",
        "cellView": "form"
      },
      "source": [
        "#@title <font size=\"5\"> ឵឵<i>← Mount your GDrive</font> { vertical-output: true }\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "pathDoneCMD = f'{HOME}/doneCMD.sh'\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ttmg.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/yunooooo/gcct/master/res/ttmg.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ttmg.py\")\n",
        "\n",
        "from ttmg import (\n",
        "    loadingAn,\n",
        "    textAn,\n",
        ")\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Installing Dependencies...\", ty='twg')\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "clear_output()\n",
        "print('Drive mounted.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQaSL55IXhjx"
      },
      "source": [
        "#@title Select Source of Pictures\n",
        "\n",
        "#text = 'value' #@param {type:\"string\"}\n",
        "Choices = 'Online images' #@param [\"Online images\", \"Personal GDrive images\"]\n",
        "\n",
        "\n",
        "#print(text)\n",
        "print('Selected: ', Choices)\n",
        "#print(text_and_dropdown)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvgLweebMURt"
      },
      "source": [
        "#@title ←  Enter address of GDrive folder <font size=\"2\"> (If selected personal photos option)</font>\n",
        "bool_personal = False\n",
        "Address = '' #@param {type:\"string\"}\n",
        "#Choices = 'Personal GDrive images' #@param [\"Online images\", \"Personal GDrive images\"]\n",
        "# Names_lower = Names.lower().replace(' ', '_')\n",
        "# var_list = Names_lower.split(\",\")\n",
        "# #print(Names)\n",
        "# my_list = Names.split(\",\")\n",
        "drive_path = '/content/drive'\n",
        "final_address = os.path.join(drive_path,Address)\n",
        "if (len(Address)>0):\n",
        "    bool_personal = True\n",
        "    print('Final Address: ')\n",
        "    print(final_address)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soBZ2XD1nSkd"
      },
      "source": [
        "#@title ← Enter names of persons <font size=\"2\"> (If selected Online Images) (comma separated) </font>\n",
        "\n",
        "Names = 'Alan Grant, Claire Dearing, Ellie Sattler, Ian Malcolm, John Hammond,Owen Grady' #@param {type:\"string\"}\n",
        "#Choices = 'Personal GDrive images' #@param [\"Online images\", \"Personal GDrive images\"]\n",
        "Names_lower = Names.lower().replace(' ', '_')\n",
        "var_list = Names_lower.split(\",\")\n",
        "#print(Names)\n",
        "my_list = Names.split(\",\")\n",
        "print('Selected: ')\n",
        "print(*my_list, sep = \", \")  \n",
        "\n",
        "#print(text_and_dropdown)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxeRtlJtu2he"
      },
      "source": [
        "#@title ← Enter output directory for downloading images\n",
        "\n",
        "Directory = 'my_dataset' #@param {type:\"string\"}\n",
        "#Choices = 'Personal GDrive images' #@param [\"Online images\", \"Personal GDrive images\"]\n",
        "# Names_lower = Names.lower().replace(' ', '_')\n",
        "# var_list = Names_lower.split(\",\")\n",
        "#print(Names)\n",
        "# my_list = Names.split(\",\")\n",
        "# user_output = 'datasetv7'\n",
        "output_directory = os.path.join(\"drive/MyDrive/\",Directory)\n",
        "\n",
        "print('Final directory: ')\n",
        "print(output_directory)  \n",
        "\n",
        "#print(text_and_dropdown)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng-bvwgVw9em",
        "cellView": "form"
      },
      "source": [
        "#@title ← How many images each person you want  <font size=\"2\">(30-50 are enough)</font>\n",
        "\n",
        "Number = \"2\" #@param {type:\"string\"}\n",
        "Number = int(Number)\n",
        "#Choices = 'Personal GDrive images' #@param [\"Online images\", \"Personal GDrive images\"]\n",
        "# Names_lower = Names.lower().replace(' ', '_')\n",
        "# var_list = Names_lower.split(\",\")\n",
        "#print(Names)\n",
        "# my_list = Names.split(\",\")\n",
        "# user_output = 'datasetv7'\n",
        "# output_directory = os.path.join(\"drive/MyDrive/\",Directory)\n",
        "\n",
        "#print('Final directory: ')\n",
        "print(Number)  \n",
        "\n",
        "#print(text_and_dropdown)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31LlWyHyz3No"
      },
      "source": [
        "#@title ← Download the images  <font size=\"2\">(30-50 are enough)</font>\n",
        "\n",
        "categories={}\n",
        "for i in range(len(my_list)):\n",
        "    categories[var_list[i]] = my_list[i]\n",
        "img_paths = {}\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Downloading images...\", ty='twg')\n",
        "\n",
        "for query, name in categories.items():\n",
        "    # img_paths[name] = download_images(query=query, \n",
        "    #                                   output_directory=output_directory,\n",
        "    #                                   image_directory=name)\n",
        "    downloader.download(name, limit=Number,  output_dir=output_directory, \n",
        "    adult_filter_off=True, force_replace=False, timeout=60)\n",
        "    #clear_output()\n",
        "clear_output()\n",
        "print(\"Downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XL0HjFZQ3-s"
      },
      "source": [
        "# Face Encodings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioZJWDGmTnS9"
      },
      "source": [
        "#@title ← To get face encodings of all images  <font size=\"2\">(30-50 are enough)</font>\n",
        "\n",
        "if (bool_personal):\n",
        "  output_directory =  final_address\n",
        "\n",
        "imagePaths = list(paths.list_images(os.path.join('/content/',output_directory)))\n",
        "\n",
        "knownEncodings = []\n",
        "knownNames = []\n",
        "\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "  if (i%20==0):    \n",
        "      print(\"[INFO] processing image {}/{}\".format(i + 1,\n",
        "        len(imagePaths)))\n",
        "  name = imagePath.split(os.path.sep)[-2]\n",
        "  image = cv2.imread(imagePath)\n",
        "  if image is None:\n",
        "      print(\"[INFO] deleting: {}\".format(imagePath))\n",
        "      os.remove(imagePath)\n",
        "      continue\n",
        "  rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  boxes = face_recognition.face_locations(rgb,\n",
        "    model=\"hog\")\n",
        "  encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "  for encoding in encodings:\n",
        "    knownEncodings.append(encoding)\n",
        "    knownNames.append(name)\n",
        "clear_output()\n",
        "print(\"Processed all %d images\" % (len(imagePaths)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmMBEDKeTtc-",
        "cellView": "form"
      },
      "source": [
        "#@title ← To serialize face encodings of all images \n",
        "print(\"[INFO] serializing encodings...\")\n",
        "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
        "f = open(\"encodings.pickle\", \"wb\")\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()\n",
        "clear_output()\n",
        "print(\"Serialized the encoding\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlyBrf3mUScj"
      },
      "source": [
        "# Testing on a photo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vwzryLVVsO7p"
      },
      "source": [
        "#@title ←  Upload test image\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "key, value = list(uploaded.items())[0]\n",
        "filename=key\n",
        "clear_output()\n",
        "print(\"Image loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHLXoYjbUYbt",
        "cellView": "form"
      },
      "source": [
        "#@title ←  Results on test image\n",
        "#print(\"[INFO] loading encodings...\")\n",
        "data = pickle.loads(open(\"/content/encodings.pickle\", \"rb\").read())\n",
        "# load the input image and convert it from BGR to RGB\n",
        "image = cv2.imread(os.path.join('/content/',filename))\n",
        "image = imutils.resize(image, width=500)\n",
        "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# detect the (x, y)-coordinates of the bounding boxes corresponding\n",
        "# to each face in the input image, then compute the facial embeddings\n",
        "# for each face\n",
        "#print(\"[INFO] recognizing faces...\")\n",
        "boxes = face_recognition.face_locations(rgb,\n",
        "\tmodel=\"cnn\")\n",
        "encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "# initialize the list of names for each face detected\n",
        "names = []\n",
        "for encoding in encodings:\n",
        "\t# attempt to match each face in the input image to our known\n",
        "\t# encodings\n",
        "\tmatches = face_recognition.compare_faces(data[\"encodings\"],\n",
        "\t\tencoding)\n",
        "\tname = \"Unknown\"\n",
        "  \t# check to see if we have found a match\n",
        "\tif True in matches:\n",
        "\t\t# find the indexes of all matched faces then initialize a\n",
        "\t\t# dictionary to count the total number of times each face\n",
        "\t\t# was matched\n",
        "\t\tmatchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "\t\tcounts = {}\n",
        "\t\t# loop over the matched indexes and maintain a count for\n",
        "\t\t# each recognized face face\n",
        "\t\tfor i in matchedIdxs:\n",
        "\t\t\tname = data[\"names\"][i]\n",
        "\t\t\tcounts[name] = counts.get(name, 0) + 1\n",
        "\t\t# determine the recognized face with the largest number of\n",
        "\t\t# votes (note: in the event of an unlikely tie Python will\n",
        "\t\t# select first entry in the dictionary)\n",
        "\t\tname = max(counts, key=counts.get)\n",
        "\t\n",
        "\t# update the list of names\n",
        "\tnames.append(name)\n",
        "for ((top, right, bottom, left), name) in zip(boxes, names):\n",
        "\t# draw the predicted face name on the image\n",
        "\tcv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "\ty = top - 15 if top - 15 > 15 else top + 15\n",
        "\tcv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t0.55, (0, 255, 0), 2)\n",
        "# show the output image\n",
        "cv2_imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GJgXMjaZZpZ"
      },
      "source": [
        "# Testing on a video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ihi3WCbNmFbm"
      },
      "source": [
        "#@title ←  Upload test video\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "key, value = list(uploaded.items())[0]\n",
        "filename=key\n",
        "clear_output()\n",
        "print(\"Video loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9kjtSE3Zaen",
        "cellView": "form"
      },
      "source": [
        "#@title ←  Get face-identified video in output folder\n",
        "cap = cv2.VideoCapture(os.path.join('/content/',filename))\n",
        "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "data = pickle.loads(open(\"/content/encodings.pickle\", \"rb\").read())\n",
        "# initialize the video stream and pointer to output video file, then\n",
        "# allow the camera sensor to warm up\n",
        "vs = VideoStream(src=0).start()\n",
        "writer = None\n",
        "time.sleep(2.0)\n",
        "input=os.path.join('/content/',filename)\n",
        "#str(output_directory)+'/video_result.mp4'\n",
        "output = str(output_directory)+'/video_result.mp4'\n",
        "display_ = 1\n",
        "video_file=True\n",
        "vs = cv2.VideoCapture(input)\n",
        "cur_frame=0\n",
        "\n",
        "while True:\n",
        "  \n",
        "  if video_file:\n",
        "        (grabbed, frame) = vs.read()\n",
        "        if not grabbed:\n",
        "            break\n",
        "  else:\n",
        "        frame = vs.read()\n",
        "  cur_frame+=1\n",
        "  if (cur_frame%100==0):\n",
        "      print(\"Processing %d / %d frame\" %(cur_frame,length))\n",
        "\n",
        "  rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "  rgb = imutils.resize(frame, width=750)\n",
        "  r = frame.shape[1] / float(rgb.shape[1])\n",
        "  boxes = face_recognition.face_locations(rgb,model=\"cnn\") \n",
        "  encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "  names = []\n",
        "  for encoding in encodings:\n",
        "\n",
        "    matches = face_recognition.compare_faces(data[\"encodings\"],encoding)\n",
        "    name = \"Unknown\"  \n",
        "    if True in matches:\n",
        "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "        counts = {}\n",
        "\n",
        "        for i in matchedIdxs:\n",
        "          name = data[\"names\"][i]\n",
        "          counts[name] = counts.get(name, 0) + 1\n",
        "  \n",
        "        name = max(counts, key=counts.get)\n",
        "\n",
        "        names.append(name)\n",
        "  for ((top, right, bottom, left), name) in zip(boxes, names):\n",
        "\n",
        "        top = int(top * r)\n",
        "        right = int(right * r)\n",
        "        bottom = int(bottom * r)\n",
        "        left = int(left * r)\n",
        "\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom),\n",
        "          (0, 255, 0), 2)\n",
        "        y = top - 15 if top - 15 > 15 else top + 15\n",
        "        cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "          0.75, (0, 255, 0), 2)\n",
        "  if writer is None and output is not None:\n",
        "      fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "      writer = cv2.VideoWriter(output, fourcc, 20,\n",
        "        (frame.shape[1], frame.shape[0]), True)\n",
        "  if writer is not None:\n",
        "    writer.write(frame)\n",
        "\n",
        "vs.release()\n",
        "\n",
        "if writer is not None:\n",
        "  writer.release()\n",
        "clear_output()\n",
        "print('Saved video to: ',end='')\n",
        "print(str(output_directory)+'/video_result.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjdb2ihP0rCY"
      },
      "source": [
        "# Clustering and renaming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5L3zcAg0wfg",
        "cellView": "form"
      },
      "source": [
        "#@title ← See Montage of similar faces\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Building Montage...\", ty='twg')\n",
        "dataset_cluster = output_directory\n",
        "#print(\"[INFO] quantifying faces...\")\n",
        "imagePaths = list(paths.list_images(dataset_cluster))\n",
        "data = []\n",
        "imagePaths.reverse()\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "  # load the input image and convert it from RGB (OpenCV ordering)\n",
        "  # to dlib ordering (RGB)\n",
        "  if((i+1)%50==0):\n",
        "    print(\"[INFO] processing image {}/{}\".format(i + 1,\n",
        "      len(imagePaths)))\n",
        "  #print(imagePath)\n",
        "  image = cv2.imread(imagePath)\n",
        "  if image is None:\n",
        "      #print(\"[INFO] deleting: {}\".format(imagePath))\n",
        "      os.remove(imagePath)\n",
        "      continue\n",
        "  else:\n",
        "      rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      boxes = face_recognition.face_locations(rgb,\n",
        "        model='hog')\n",
        "        # compute the facial embedding for the face\n",
        "      encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "      d = [{\"imagePath\": imagePath, \"loc\": box, \"encoding\": enc}\n",
        "        for (box, enc) in zip(boxes, encodings)]\n",
        "      data.extend(d)\n",
        "#print(\"[INFO] serializing encodings...\")\n",
        "f = open('encodings_cluster.pickle', \"wb\")\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()\n",
        "#print(\"[INFO] loading encodings...\")\n",
        "data = pickle.loads(open('encodings_cluster.pickle', \"rb\").read())\n",
        "data = np.array(data)\n",
        "encodings = [d[\"encoding\"] for d in data]\n",
        "#print(\"[INFO] clustering...\")\n",
        "clt = DBSCAN(metric=\"euclidean\", n_jobs=-1)\n",
        "clt.fit(encodings)\n",
        "# determine the total number of unique faces found in the dataset\n",
        "labelIDs = np.unique(clt.labels_)\n",
        "numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
        "clear_output()\n",
        "print(\"[INFO] # Unique faces: {}\".format(numUniqueFaces))\n",
        "for labelID in labelIDs[1:]:\n",
        "  # find all indexes into the `data` array that belong to the\n",
        "  # current label ID, then randomly sample a maximum of 25 indexes\n",
        "  # from the set\n",
        "  print(\"[INFO] faces for face ID: {}\".format(labelID))\n",
        "  idxs = np.where(clt.labels_ == labelID)[0]\n",
        "  idxs = np.random.choice(idxs, size=min(25, len(idxs)),\n",
        "    replace=False)\n",
        "  # initialize the list of faces to include in the montage\n",
        "  faces = []\n",
        "  for i in idxs:\n",
        "    # load the input image and extract the face ROI\n",
        "    #print(data[i][\"imagePath\"])\n",
        "    image = cv2.imread(data[i][\"imagePath\"])\n",
        "    (top, right, bottom, left) = data[i][\"loc\"]\n",
        "    face = image[top:bottom, left:right]\n",
        "    # force resize the face ROI to 96x96 and then add it to the\n",
        "    # faces montage list\n",
        "    face = cv2.resize(face, (96, 96))\n",
        "    faces.append(face)\n",
        "  montage = build_montages(faces, (96, 96), (5, 5))[0]\n",
        "  \n",
        "  # show the output montage\n",
        "  title = \"Face ID #{}\".format(labelID)\n",
        "  title = \"Unknown Faces\" if labelID == -1 else title\n",
        "  cv2_imshow(montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IehZhyoZ6xNF",
        "cellView": "form"
      },
      "source": [
        "#@title ← Enter names of persons by ID <font size=\"2\"> (Serialwise) (comma separated) </font>\n",
        "\n",
        "Cluster_Names = 'face1,face2,face3,face4,face5,face6' #@param {type:\"string\"}\n",
        "#Names = 'abc' #@param {type:\"string\"}\n",
        "#Choices = 'Personal GDrive images' #@param [\"Online images\", \"Personal GDrive images\"]\n",
        "Cluster_Names_lower = Cluster_Names.lower().replace(' ', '_')\n",
        "Cluster_var_list = Cluster_Names_lower.split(\",\")\n",
        "#print(Names)\n",
        "Cluster_my_list =Cluster_Names.split(\",\")\n",
        "if ((len(labelIDs)-1) == len(Cluster_my_list)):\n",
        "  print(\"Selected names:\")\n",
        "  for i in range(len(labelIDs)-1):\n",
        "    print(labelIDs[i+1], ':',Cluster_my_list[i] )\n",
        "else :\n",
        "    print(\"Incorrect number of names entered\")\n",
        "\n",
        "# print('Selected: ')\n",
        "# print(*Cluster_my_list, sep = \", \")  \n",
        "\n",
        "#print(text_and_dropdown)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4PDMBaoEVDY",
        "cellView": "form"
      },
      "source": [
        "#@title ← Run to start renaming files\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Renaming files...\", ty='twg')\n",
        "\n",
        "count=0\n",
        "for labelID in labelIDs[1:]:\n",
        "  idxs = np.where(clt.labels_ == labelID)[0]\n",
        "  idxs = np.random.choice(idxs, size=(len(idxs)),\n",
        "    replace=False)\n",
        "  faces = []\n",
        "  for i in idxs:\n",
        "    src = data[i][\"imagePath\"]\n",
        "    a = src.split(os.path.sep)\n",
        "    b = a[:-1]\n",
        "    c = '/'.join(b)\n",
        "    var = Cluster_my_list[labelID]\n",
        "    d = os.path.join(c,str(var)+'_'+str(i)+'.jpg') \n",
        "    os.rename(src, d) \n",
        "    count+=1\n",
        "clear_output()\n",
        "print(\" %d Files renamed\" % count)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}